{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, auc_score\n",
    "\n",
    "import parallel\n",
    "\n",
    "N_JOBS = 10\n",
    "ORI_ID_USER = 'userId'\n",
    "ORI_ID_ITEM = 'movieId'\n",
    "\n",
    "SEQ_ID_USER = 'user_id'\n",
    "SEQ_ID_ITEM = 'item_id'\n",
    "\n",
    "SOURCE = os.path.expanduser(\"~/Classification_RecSys\")\n",
    "\n",
    "#Read Data\n",
    "train = pd.read_hdf(\n",
    "    os.path.join(SOURCE, 'data/train.hdf'))\n",
    "\n",
    "test = pd.read_hdf(\n",
    "    os.path.join(SOURCE, 'data/test.hdf'))\n",
    "\n",
    "item_catalogue = pd.read_hdf(\n",
    "    os.path.join(SOURCE, 'data/item_catalog.hdf'))\n",
    "\n",
    "user_id_translator = pd.concat(\n",
    "    [train, test], axis=0\n",
    ").drop_duplicates([\n",
    "    SEQ_ID_USER])[[ORI_ID_USER, SEQ_ID_USER]]\n",
    "user_id_translator.sort_values(SEQ_ID_USER, inplace=True)\n",
    "\n",
    "item_id_translator = pd.concat(\n",
    "    [train, test], axis=0\n",
    ").drop_duplicates([\n",
    "    SEQ_ID_ITEM])[[ORI_ID_ITEM, SEQ_ID_ITEM]]\n",
    "item_id_translator.sort_values(SEQ_ID_ITEM, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num users: 257179 num items: 7306 (Transactions)\n"
     ]
    }
   ],
   "source": [
    "userids = set(\n",
    "    train[SEQ_ID_USER]\n",
    ").union(\n",
    "    test[SEQ_ID_USER])\n",
    "\n",
    "itemids = set(\n",
    "    train[SEQ_ID_ITEM]\n",
    ").union(\n",
    "    test[SEQ_ID_ITEM])\n",
    "\n",
    "num_users = len(userids)\n",
    "num_items = len(itemids)\n",
    "\n",
    "print(\"num users: %s num items: %s (Transactions)\" % (\n",
    "    num_users, \n",
    "    num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecSys Train/Test Matrix and User/Item Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<257179x7306 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11055959 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_coo = scipy.sparse.coo_matrix(\n",
    "        (\n",
    "            np.ones(train.shape[0]),\n",
    "            (train[SEQ_ID_USER], train[SEQ_ID_ITEM])\n",
    "        ), \n",
    "        shape=(num_users, num_items))\n",
    "train_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<257179x7306 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 672 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_coo = scipy.sparse.coo_matrix(\n",
    "        (\n",
    "            np.ones(test.shape[0]),\n",
    "            (test[SEQ_ID_USER], test[SEQ_ID_ITEM])\n",
    "        ),\n",
    "        shape=(num_users, num_items))\n",
    "test_coo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "def get_precison_test(id_user):\n",
    "    relevants = set(\n",
    "        test[test[SEQ_ID_USER] == id_user][SEQ_ID_ITEM].tolist()\n",
    "    )\n",
    "\n",
    "    scores = model.predict(\n",
    "        id_user,\n",
    "        np.arange(num_items)\n",
    "    )\n",
    "    \n",
    "    top_k_rec = np.argsort(-scores)[:top_k].astype(int).tolist()\n",
    "\n",
    "    precision_local = len(relevants.intersection(top_k_rec)) / top_k\n",
    "\n",
    "    return [id_user, precision_local]\n",
    "\n",
    "def get_precison_train(id_user):\n",
    "    relevants = set(\n",
    "        train[train[SEQ_ID_USER] == id_user][SEQ_ID_ITEM].tolist()\n",
    "    )\n",
    "\n",
    "    scores = model.predict(\n",
    "        id_user, \n",
    "        np.arange(num_items)\n",
    "    )\n",
    "    \n",
    "    top_k_rec = np.argsort(-scores)[:top_k].astype(int).tolist()\n",
    "\n",
    "    precision_local = len(relevants.intersection(top_k_rec)) / top_k\n",
    "\n",
    "    return [id_user, precision_local]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1]\n",
      "\tTrain AUC: 0.9695274.5f\n",
      "\tTest AUC: 0.852294.5f\n",
      "\tTrain Precision @10: 0.67911\n",
      "\tTest Precision @10: 0.00521\n",
      "Elapsed Time: 0.72min\n",
      "[epoch: 2]\n",
      "\tTrain AUC: 0.97382015.5f\n",
      "\tTest AUC: 0.84858096.5f\n",
      "\tTrain Precision @10: 0.70010\n",
      "\tTest Precision @10: 0.00476\n",
      "Elapsed Time: 0.69min\n",
      "[epoch: 3]\n",
      "\tTrain AUC: 0.9763002.5f\n",
      "\tTest AUC: 0.8522096.5f\n",
      "\tTrain Precision @10: 0.71241\n",
      "\tTest Precision @10: 0.00446\n",
      "Elapsed Time: 0.7min\n",
      "[epoch: 4]\n",
      "\tTrain AUC: 0.9779674.5f\n",
      "\tTest AUC: 0.85497737.5f\n",
      "\tTrain Precision @10: 0.72250\n",
      "\tTest Precision @10: 0.00476\n",
      "Elapsed Time: 0.7min\n",
      "[epoch: 5]\n",
      "\tTrain AUC: 0.9791786.5f\n",
      "\tTest AUC: 0.8550285.5f\n",
      "\tTrain Precision @10: 0.73007\n",
      "\tTest Precision @10: 0.00580\n",
      "Elapsed Time: 0.7min\n",
      "[epoch: 6]\n",
      "\tTrain AUC: 0.98012245.5f\n",
      "\tTest AUC: 0.8566438.5f\n",
      "\tTrain Precision @10: 0.73370\n",
      "\tTest Precision @10: 0.00580\n",
      "Elapsed Time: 0.69min\n",
      "[epoch: 7]\n",
      "\tTrain AUC: 0.9808799.5f\n",
      "\tTest AUC: 0.8574718.5f\n",
      "\tTrain Precision @10: 0.73794\n",
      "\tTest Precision @10: 0.00595\n",
      "Elapsed Time: 0.69min\n",
      "[epoch: 8]\n",
      "\tTrain AUC: 0.9815105.5f\n",
      "\tTest AUC: 0.8590537.5f\n",
      "\tTrain Precision @10: 0.74198\n",
      "\tTest Precision @10: 0.00565\n",
      "Elapsed Time: 0.69min\n",
      "[epoch: 9]\n",
      "\tTrain AUC: 0.9820437.5f\n",
      "\tTest AUC: 0.8588191.5f\n",
      "\tTrain Precision @10: 0.74339\n",
      "\tTest Precision @10: 0.00521\n",
      "Elapsed Time: 0.68min\n",
      "[epoch: 10]\n",
      "\tTrain AUC: 0.9825028.5f\n",
      "\tTest AUC: 0.8586982.5f\n",
      "\tTrain Precision @10: 0.74369\n",
      "\tTest Precision @10: 0.00551\n",
      "Elapsed Time: 0.7min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "epochs_incr = 1\n",
    "epochs = 10\n",
    "\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "\n",
    "precision_train = []\n",
    "precision_test = []\n",
    "train_auc = []\n",
    "test_auc = []\n",
    "\n",
    "train_sample_ids = train.sample(1000)[SEQ_ID_USER].unique()\n",
    "\n",
    "iterations = range(epochs_incr, epochs+epochs_incr, epochs_incr)\n",
    "\n",
    "for epoch in iterations:\n",
    "    print(\"[epoch: %s]\" % epoch)\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.fit_partial(\n",
    "        train_coo, \n",
    "        epochs=epochs_incr,\n",
    "        num_threads=N_JOBS)\n",
    "    \n",
    "    train_auc_local = auc_score(\n",
    "        model,\n",
    "        train_coo,\n",
    "        num_threads=N_JOBS).mean()\n",
    "    train_auc.append(train_auc_local)\n",
    "    \n",
    "    test_auc_local = auc_score(\n",
    "        model,\n",
    "        test_coo,\n",
    "        num_threads=N_JOBS).mean()\n",
    "    test_auc.append(test_auc_local)\n",
    "    \n",
    "    print('\\tTrain AUC: %s.5f' % train_auc_local)\n",
    "    print('\\tTest AUC: %s.5f' % test_auc_local)\n",
    "    \n",
    "    precision_train_local = np.array(parallel.apply(\n",
    "        get_precison_train,\n",
    "        train_sample_ids,\n",
    "        n_jobs=N_JOBS))\n",
    "    precision_train.append(precision_train_local)\n",
    "    \n",
    "    precision_test_local = np.array(parallel.apply(\n",
    "        get_precison_test,\n",
    "        test[SEQ_ID_USER].unique(),\n",
    "        n_jobs=N_JOBS))\n",
    "    precision_test.append(precision_test_local)\n",
    "    \n",
    "    print(\"\\tTrain Precision @10: %.5f\" % (\n",
    "        precision_train_local[:,1].mean()))\n",
    "    print(\"\\tTest Precision @10: %.5f\" % (\n",
    "        precision_test_local[:,1].mean()))\n",
    "\n",
    "    print(\"Elapsed Time: %smin\" % round(\n",
    "        (time.time() - start_time)/60, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Precision / Test Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Example 0\n",
      "--------\n",
      "Items in train (34, 9) Drama:68|Thriller:28|Comedy:26|Romance:15|Crime:15|Action:15|History:9|Documentary:9|Adventure:9|War:6|Science Fiction:6|Music:6|Foreign:6|Family:6|Mystery:3|Horror:3\n",
      "User 86748\n",
      "                                                title  \\\n",
      "Known Positives                          Big Bad Mama   \n",
      "Recommended      Confession of a Child of the Century   \n",
      "Recommended                               5 Card Stud   \n",
      "Recommended                            License to Wed   \n",
      "Recommended                  The Million Dollar Hotel   \n",
      "Recommended                The Passion of Joan of Arc   \n",
      "Recommended                              Loose Screws   \n",
      "Recommended        Terminator 3: Rise of the Machines   \n",
      "Recommended                                The Tunnel   \n",
      "Recommended                           Monsoon Wedding   \n",
      "Recommended                      Beauty and the Beast   \n",
      "\n",
      "                                              genres    year  \n",
      "Known Positives       [Action, Comedy, Crime, Drama]  1974.0  \n",
      "Recommended                                  [Drama]  2012.0  \n",
      "Recommended              [Action, Western, Thriller]  1968.0  \n",
      "Recommended                                 [Comedy]  2007.0  \n",
      "Recommended                        [Drama, Thriller]  2000.0  \n",
      "Recommended                         [Drama, History]  1928.0  \n",
      "Recommended                                 [Comedy]  1985.0  \n",
      "Recommended      [Action, Thriller, Science Fiction]  2003.0  \n",
      "Recommended                        [Science Fiction]  1933.0  \n",
      "Recommended                 [Comedy, Drama, Romance]  2001.0  \n",
      "Recommended                [Drama, Fantasy, Romance]  1946.0  \n",
      "------\n",
      "Example 1\n",
      "--------\n",
      "Items in train (19, 9) Drama:53|Thriller:26|Science Fiction:21|Foreign:16|Comedy:16|Action:16|Romance:11|Mystery:11|Horror:11|History:11|Adventure:11|Western:5|TV Movie:5|Fantasy:5|Documentary:5\n",
      "User 219245\n",
      "                                                title  \\\n",
      "Known Positives                         I Spy Returns   \n",
      "Recommended      Confession of a Child of the Century   \n",
      "Recommended                                 Longitude   \n",
      "Recommended                  The Million Dollar Hotel   \n",
      "Recommended                               Silent Hill   \n",
      "Recommended                            Batman Returns   \n",
      "Recommended                           Caesar Must Die   \n",
      "Recommended                     To Kill a Mockingbird   \n",
      "Recommended                           The Dawn Patrol   \n",
      "Recommended                         Woman of the Lake   \n",
      "Recommended                Cheerleaders' Wild Weekend   \n",
      "\n",
      "                                                genres    year  \n",
      "Known Positives  [TV Movie, Action, Adventure, Comedy]  1994.0  \n",
      "Recommended                                    [Drama]  2012.0  \n",
      "Recommended                 [TV Movie, Drama, History]  2000.0  \n",
      "Recommended                          [Drama, Thriller]  2000.0  \n",
      "Recommended                          [Horror, Mystery]  2006.0  \n",
      "Recommended                          [Action, Fantasy]  1992.0  \n",
      "Recommended                       [Drama, Documentary]  2012.0  \n",
      "Recommended                             [Crime, Drama]  1962.0  \n",
      "Recommended                       [Action, War, Drama]  1930.0  \n",
      "Recommended                                    [Drama]  1966.0  \n",
      "Recommended                            [Comedy, Crime]  1979.0  \n"
     ]
    }
   ],
   "source": [
    "def sample_recommendation(model, data_coo, id_user):\n",
    "    \n",
    "    local_train = train[train[SEQ_ID_USER] == id_user]\n",
    "    \n",
    "    genres = {}\n",
    "    for x in item_catalogue.loc[local_train[SEQ_ID_ITEM]]['genres']:\n",
    "        for y in x:\n",
    "            if y in genres:\n",
    "                genres[y] += 1\n",
    "            else:\n",
    "                genres[y] = 1\n",
    "        \n",
    "    genres = pd.Series(genres).sort_values(ascending=False)\n",
    "    genres = ((genres / local_train.shape[0]).round(2) * 100).astype(int)\n",
    "    genres = genres.to_dict()\n",
    "    genres = [\"%s:%s\" %(genre, genre_cnt) for genre, genre_cnt in genres.items()]\n",
    "    genres = \"|\".join(genres)\n",
    "    \n",
    "    #genres = local_train['genres'].value_counts() / local_train.shape[0]\n",
    "    print(\"Items in train\", local_train.shape, genres)\n",
    "    \n",
    "    known_positives = data_coo.tocsr()[id_user].indices\n",
    "    known_positives = item_catalogue.loc[known_positives]\n",
    "    \n",
    "    scores = model.predict(\n",
    "        id_user, \n",
    "        np.arange(num_items))\n",
    "    \n",
    "    ranking = np.argsort(-scores)\n",
    "    \n",
    "    top_items = item_catalogue.loc[ranking[:top_k]]\n",
    "\n",
    "    print(\"User %s\" % id_user)\n",
    "\n",
    "    known_positives.index = ['Known Positives'] * known_positives.shape[0]\n",
    "    top_items.index = ['Recommended'] * top_items.shape[0]\n",
    "    \n",
    "    print(pd.concat([known_positives, top_items])[[\n",
    "        'title', 'genres', 'year'\n",
    "    ]])\n",
    "\n",
    "for it in range(2):\n",
    "    print(\"------\\nExample %s\\n--------\" % it)\n",
    "    sample_recommendation(\n",
    "        model=model,\n",
    "        data_coo=test_coo,\n",
    "        id_user=test.sample(1)[SEQ_ID_USER].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_emb = pd.DataFrame(model.item_embeddings)\n",
    "item_emb = item_emb.add_prefix(\"i_latent_\")\n",
    "\n",
    "user_emb = pd.DataFrame(model.user_embeddings)\n",
    "user_emb = user_emb.add_prefix(\"u_latent_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User emb. shape (257175, 10)\n",
      "Item emb. shape (5843, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"User emb. shape\", user_emb.shape)\n",
    "print(\"Item emb. shape\", item_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ui_trans = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ids = ui_trans[[SEQ_ID_USER, ORI_ID_USER]].drop_duplicates()\n",
    "item_ids = ui_trans[[SEQ_ID_ITEM, ORI_ID_ITEM]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_emb[ORI_ID_USER] = user_ids[ORI_ID_USER]\n",
    "item_emb[ORI_ID_ITEM] = item_ids[ORI_ID_ITEM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_emb.set_index(ORI_ID_USER, inplace=True)\n",
    "item_emb.set_index(ORI_ID_ITEM, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans_emb_user = user_emb.loc[train[ORI_ID_USER]]\n",
    "train_trans_emb_item = item_emb.loc[train[ORI_ID_ITEM]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import XGB as xgb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
