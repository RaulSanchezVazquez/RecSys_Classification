{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Download dataset:\n",
    "\n",
    "https://www.kaggle.com/rounakbanik/the-movies-dataset\n",
    "\"\"\"\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore');\n",
    "\n",
    "import os\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "import parallel\n",
    "\n",
    "N_JOBS = 10\n",
    "SOURCE = os.path.expanduser(\"~/RecSys_Classification/\")\n",
    "\n",
    "#Read Data\n",
    "ratings_path = os.path.join(\n",
    "    SOURCE,\n",
    "    'data/ratings.csv')\n",
    "ratings = pd.read_csv(ratings_path)\n",
    "\n",
    "item_f_path = os.path.join(\n",
    "    SOURCE,\n",
    "    'data/movies_metadata.csv')\n",
    "item_features = pd.read_csv(item_f_path)\n",
    "\n",
    "credits_path = os.path.join(\n",
    "    SOURCE,\n",
    "    'data/credits.csv')\n",
    "credits = pd.read_csv(credits_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Data\n",
    "item_features['id'] = pd.to_numeric(\n",
    "    item_features['id'], \n",
    "    errors='coerce')\n",
    "credits['id'] = pd.to_numeric(\n",
    "    credits['id'], \n",
    "    errors='coerce')\n",
    "\n",
    "credits = credits[~credits['id'].isnull()]\n",
    "item_features = item_features[~item_features['id'].isnull()]\n",
    "\n",
    "item_features.drop_duplicates('id', inplace=True)\n",
    "credits.drop_duplicates('id', inplace=True)\n",
    "\n",
    "item_features['id'] = item_features['id'].astype(int)\n",
    "credits['id'] = credits['id'].astype(int)\n",
    "\n",
    "item_features.index = item_features['id']\n",
    "credits.index = credits['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = set(\n",
    "    item_features.index.tolist()\n",
    ").intersection(\n",
    "    credits.index.tolist()\n",
    ")\n",
    "idx = list(idx)\n",
    "len(idx)\n",
    "\n",
    "item_features = item_features[item_features.index.isin(idx)]\n",
    "credits = credits[credits.index.isin(idx)]\n",
    "\n",
    "item_features = pd.concat([\n",
    "    item_features,\n",
    "    credits.loc[item_features.index]],\n",
    "    axis=1)\n",
    "item_features = item_features.drop('id', axis=1)\n",
    "\n",
    "ratings = ratings[ratings['movieId'].isin(item_features.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Classification Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fantasy|Romance|Animation|Drama|Horror|History|Mystery|Music|Thriller|Documentary|Western|Science Fiction|Adventure|War|Action|Comedy|TV Movie|Family|Crime|Foreign\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Horror</th>\n",
       "      <th>History</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Music</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Western</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>War</th>\n",
       "      <th>Action</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Family</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Foreign</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8844</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15602</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11862</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Fantasy   Romance  Animation     Drama  Horror  History  Mystery  \\\n",
       "id                                                                         \n",
       "862    0.000000  0.000000   0.333333  0.000000     0.0      0.0      0.0   \n",
       "8844   0.333333  0.000000   0.000000  0.000000     0.0      0.0      0.0   \n",
       "15602  0.000000  0.500000   0.000000  0.000000     0.0      0.0      0.0   \n",
       "31357  0.000000  0.333333   0.000000  0.333333     0.0      0.0      0.0   \n",
       "11862  0.000000  0.000000   0.000000  0.000000     0.0      0.0      0.0   \n",
       "\n",
       "       Music  Thriller  Documentary  Western  Science Fiction  Adventure  War  \\\n",
       "id                                                                              \n",
       "862      0.0       0.0          0.0      0.0              0.0   0.000000  0.0   \n",
       "8844     0.0       0.0          0.0      0.0              0.0   0.333333  0.0   \n",
       "15602    0.0       0.0          0.0      0.0              0.0   0.000000  0.0   \n",
       "31357    0.0       0.0          0.0      0.0              0.0   0.000000  0.0   \n",
       "11862    0.0       0.0          0.0      0.0              0.0   0.000000  0.0   \n",
       "\n",
       "       Action    Comedy  TV Movie    Family  Crime  Foreign  \n",
       "id                                                           \n",
       "862       0.0  0.333333       0.0  0.333333    0.0      0.0  \n",
       "8844      0.0  0.000000       0.0  0.333333    0.0      0.0  \n",
       "15602     0.0  0.500000       0.0  0.000000    0.0      0.0  \n",
       "31357     0.0  0.333333       0.0  0.000000    0.0      0.0  \n",
       "11862     0.0  1.000000       0.0  0.000000    0.0      0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def literal_eval_(x):\n",
    "    try:\n",
    "        return literal_eval(x)\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "#Getting target\n",
    "item_features['genres'] = item_features['genres'].apply(\n",
    "    lambda x: [y['name'] for y in literal_eval_(x) ])\n",
    "\n",
    "genres = item_features['genres'].tolist() \n",
    "all_genres = list(set([y for x in genres for y in x]))\n",
    "print(\"|\".join(all_genres))\n",
    "\n",
    "all_genres = pd.Series(all_genres)\n",
    "all_genres.head()\n",
    "\n",
    "target = item_features['genres'].apply(\n",
    "    lambda x: all_genres.isin(x))\n",
    "\n",
    "target.columns = all_genres\n",
    "target = target.apply(\n",
    "    lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item Features\n",
    "\n",
    "Read data an basic data transformation (genres as array & target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|shqip|Italiano|Esperanto|қазақ|English|Malti|Slovenščina|Nederlands|普通话|Español|한국어/조선말|日本語|Polski|Português|Wolof|ภาษาไทย|български език|Bamanankan|پښتو|Somali|Bosanski|Pусский|Dansk|हिन्दी|Український|ozbek|Hausa|Français|??????|Kiswahili|ελληνικά|Bokmål|العربية|Český|தமிழ்|עִבְרִית|Íslenska|Srpski|euskera|Tiếng Việt|Deutsch|Galego|ქართული|Fulfulde|Bahasa melayu|اردو|Eesti|বাংলা|తెలుగు|Azərbaycan|svenska|Latviešu|suomi|беларуская мова|Română|isiZulu|Bahasa indonesia|Hrvatski|Kinyarwanda|Gaeilge|Cymraeg|Norsk|Türkçe|Lietuvikai|Slovenčina|No Language|فارسی|Afrikaans|Latin|Magyar|ਪੰਜਾਬੀ|Català|广州话 / 廣州話|?????\n"
     ]
    }
   ],
   "source": [
    "#Year\n",
    "item_features['year'] = pd.to_datetime(\n",
    "    item_features['release_date'], \n",
    "    errors='coerce').dt.year\n",
    "\n",
    "def count_json(x):\n",
    "    try:\n",
    "        return len(literal_eval(x))\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "#Crew and Cast Sizes\n",
    "for f in ['cast', 'crew']:\n",
    "    new_feature = \"%s_size\" % f\n",
    "    item_features[new_feature] = parallel.apply(\n",
    "        count_json,\n",
    "        item_features[f],\n",
    "        n_jobs=N_JOBS)\n",
    "\n",
    "#Ensure Numeric\n",
    "for f in ['vote_count', 'vote_average', 'budget', 'popularity', 'revenue']:\n",
    "    item_features[f] = pd.to_numeric(\n",
    "        item_features[f], \n",
    "        errors='coerce')\n",
    "    \n",
    "#Language\n",
    "def parse_spok_lan(x):\n",
    "    return [y['name'] for y in literal_eval_(x)]\n",
    "\n",
    "item_features['spoken_languages'] = parallel.apply(\n",
    "    parse_spok_lan,\n",
    "    item_features['spoken_languages'])\n",
    "\n",
    "languages = item_features['spoken_languages']\n",
    "all_languages = list(set([y for x in languages for y in x]))\n",
    "print(\"|\".join(all_languages))\n",
    "\n",
    "all_languages = pd.Series(all_languages)\n",
    "\n",
    "spoken_languages = item_features['spoken_languages'].apply(\n",
    "    lambda x: all_languages.isin(x))\n",
    "\n",
    "spoken_languages.columns = all_languages\n",
    "spoken_languages.index = item_features.index\n",
    "\n",
    "spoken_languages = spoken_languages.add_prefix(\"language_\")\n",
    "spoken_languages.head()\n",
    "\n",
    "#Concat Num.Features and Language Features\n",
    "numeric_features = item_features[[\n",
    "    'budget',\n",
    "    'popularity',\n",
    "    'revenue',\n",
    "    'runtime',\n",
    "    'vote_average',\n",
    "    'vote_count',\n",
    "    'year',\n",
    "    'cast_size',\n",
    "    'crew_size']]\n",
    "\n",
    "i_features = pd.concat([\n",
    "    numeric_features,\n",
    "    spoken_languages.astype(int)],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>year</th>\n",
       "      <th>cast_size</th>\n",
       "      <th>crew_size</th>\n",
       "      <th>language_</th>\n",
       "      <th>...</th>\n",
       "      <th>language_Slovenčina</th>\n",
       "      <th>language_No Language</th>\n",
       "      <th>language_فارسی</th>\n",
       "      <th>language_Afrikaans</th>\n",
       "      <th>language_Latin</th>\n",
       "      <th>language_Magyar</th>\n",
       "      <th>language_ਪੰਜਾਬੀ</th>\n",
       "      <th>language_Català</th>\n",
       "      <th>language_广州话 / 廣州話</th>\n",
       "      <th>language_?????</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>30000000</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8844</th>\n",
       "      <td>65000000</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15602</th>\n",
       "      <td>0</td>\n",
       "      <td>11.712900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>16000000</td>\n",
       "      <td>3.859495</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11862</th>\n",
       "      <td>0</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         budget  popularity      revenue  runtime  vote_average  vote_count  \\\n",
       "id                                                                            \n",
       "862    30000000   21.946943  373554033.0     81.0           7.7      5415.0   \n",
       "8844   65000000   17.015539  262797249.0    104.0           6.9      2413.0   \n",
       "15602         0   11.712900          0.0    101.0           6.5        92.0   \n",
       "31357  16000000    3.859495   81452156.0    127.0           6.1        34.0   \n",
       "11862         0    8.387519   76578911.0    106.0           5.7       173.0   \n",
       "\n",
       "         year  cast_size  crew_size  language_       ...        \\\n",
       "id                                                   ...         \n",
       "862    1995.0         13        106          0       ...         \n",
       "8844   1995.0         26         16          0       ...         \n",
       "15602  1995.0          7          4          0       ...         \n",
       "31357  1995.0         10         10          0       ...         \n",
       "11862  1995.0         12          7          0       ...         \n",
       "\n",
       "       language_Slovenčina  language_No Language  language_فارسی  \\\n",
       "id                                                                 \n",
       "862                      0                     0               0   \n",
       "8844                     0                     0               0   \n",
       "15602                    0                     0               0   \n",
       "31357                    0                     0               0   \n",
       "11862                    0                     0               0   \n",
       "\n",
       "       language_Afrikaans  language_Latin  language_Magyar  language_ਪੰਜਾਬੀ  \\\n",
       "id                                                                            \n",
       "862                     0               0                0                0   \n",
       "8844                    0               0                0                0   \n",
       "15602                   0               0                0                0   \n",
       "31357                   0               0                0                0   \n",
       "11862                   0               0                0                0   \n",
       "\n",
       "       language_Català  language_广州话 / 廣州話  language_?????  \n",
       "id                                                          \n",
       "862                  0                   0               0  \n",
       "8844                 0                   0               0  \n",
       "15602                0                   0               0  \n",
       "31357                0                   0               0  \n",
       "11862                0                   0               0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat. movie title in transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_to_name = item_features['title'].to_dict()\n",
    "\n",
    "def get_title(x):\n",
    "    if x in item_id_to_name: \n",
    "        return item_id_to_name[x]\n",
    "    else:\n",
    "        np.nan\n",
    "\n",
    "ratings['title'] = parallel.apply(\n",
    "    get_title,\n",
    "    ratings['movieId'],\n",
    "    n_jobs=N_JOBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORI_ID_USER = 'userId'\n",
    "ORI_ID_ITEM = 'movieId'\n",
    "\n",
    "SEQ_ID_USER = 'user_id'\n",
    "SEQ_ID_ITEM = 'item_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['id_transaction'] = range(ratings.shape[0])\n",
    "\n",
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "ratings['timestamp'].dt.year.value_counts().sort_index()\n",
    "\n",
    "split_date = pd.datetime(\n",
    "    year=2017,\n",
    "    month=1,\n",
    "    day=1)\n",
    "\n",
    "train = ratings[ratings['timestamp'] < split_date]\n",
    "test = ratings[ratings['timestamp'] >= split_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\t11055959 (#users: 257179 #items:7300)\n",
      "Test data:\t380609 (#users: 12895 #items:5514)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\\t%s (#users: %s #items:%s)\" % (\n",
    "    train.shape[0],\n",
    "    len(train[ORI_ID_USER].unique()),\n",
    "    len(train[ORI_ID_ITEM].unique())))\n",
    "\n",
    "print(\"Test data:\\t%s (#users: %s #items:%s)\" % (\n",
    "    test.shape[0],\n",
    "    test[ORI_ID_USER].nunique(),\n",
    "    test[ORI_ID_ITEM].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign new sequencial user/item IDs (after having fixed train/test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Users:265917 #Items:7565 sparsity: 0.99431\n"
     ]
    }
   ],
   "source": [
    "IDorigin_IDuser = {}\n",
    "IDuser_IDorigin = {}\n",
    "for id_user, id_origin in enumerate(ratings[ORI_ID_USER].unique()):\n",
    "    IDorigin_IDuser[id_origin] = id_user\n",
    "    IDuser_IDorigin[id_user] = id_origin\n",
    "\n",
    "IDorigin_IDitem = {}\n",
    "IDitem_IDorigin = {}\n",
    "for id_item, id_origin in enumerate(ratings[ORI_ID_ITEM].unique()):\n",
    "    IDorigin_IDitem[id_origin] = id_item\n",
    "    IDitem_IDorigin[id_item] = id_origin\n",
    "\n",
    "num_users = len(IDorigin_IDuser)\n",
    "num_items = len(IDorigin_IDitem)\n",
    "\n",
    "ratings[SEQ_ID_USER] = ratings[ORI_ID_USER].apply(lambda x: IDorigin_IDuser[x])\n",
    "ratings[SEQ_ID_ITEM] = ratings[ORI_ID_ITEM].apply(lambda x: IDorigin_IDitem[x])\n",
    "\n",
    "train = ratings[ratings['id_transaction'].isin(train['id_transaction'])]\n",
    "test = ratings[ratings['id_transaction'].isin(test['id_transaction'])]\n",
    "\n",
    "print(\"#Users:%s #Items:%s sparsity: %s\" % (\n",
    "    num_users,\n",
    "    num_items,\n",
    "    round(1 - (ratings.shape[0] / (num_users * num_items)), 5)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_hdf(\n",
    "    os.path.join(SOURCE, \"data/train.hdf\" ), key='train')\n",
    "\n",
    "test.to_hdf(\n",
    "    os.path.join(SOURCE, \"data/test.hdf\" ), key='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build item catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-7ed593528135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitem_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mORI_ID_ITEM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m item_features[SEQ_ID_ITEM] = pd.Series(item_features['id']).apply(\n\u001b[1;32m      3\u001b[0m     lambda x: IDorigin_IDitem[x]).values\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m item_cat_f = [\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "item_features = item_features[item_features['id'].isin( ratings[ORI_ID_ITEM].unique() )]\n",
    "item_features[SEQ_ID_ITEM] = pd.Series(item_features['id']).apply(\n",
    "    lambda x: IDorigin_IDitem[x]).values\n",
    "\n",
    "item_cat_f = [\n",
    "    'title', \n",
    "    'popularity', \n",
    "    'genres', \n",
    "    'year', \n",
    "    SEQ_ID_ITEM]\n",
    "\n",
    "item_catalog = item_features[item_cat_f].copy()\n",
    "item_catalog.drop_duplicates(\n",
    "    list(set(item_cat_f)-set(['genres'])),\n",
    "    inplace=True)\n",
    "\n",
    "item_catalog.index = item_catalog[SEQ_ID_ITEM]\n",
    "\n",
    "item_catalog.sort_values('item_id', inplace=True)\n",
    "print(item_catalog.shape)\n",
    "item_catalog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_catalog.to_hdf(\n",
    "    os.path.join(SOURCE, \"data/item_catalog.hdf\" ), \n",
    "    key='item_catalog')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
